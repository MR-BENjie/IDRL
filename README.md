#IDRL
We develop IDRL, a novel multi-agent reinforcement learning framework consisting of identification and policy modules that learns the policy with identification capability. Here, we release the code about IDRL implementation in the Red-10 game, Red-10 game evrionment and visualize tool.
##IDRL Implementation in the Red-10 Game
In the directory "IDRL_in_Red_10", we release the IDRL implementation in the Red-10 Game.
<img width="500" src="https://github.com/MR-BENjie/IDRL/over_all_framework.jpg"/>
The core concept of the IDRL framework is to transform a setting with ambiguous agent identities into one with less ambiguous identities. That is, agents are empowered to intuitively infer the identity of a cooperating agent and then act upon the assumption. In the IDRL framework, we use the identification module to identify others identities first; then, the policy module, which is pretrained with appropriate action sets, generates operational rule sets. Recall that the identification module comprises relation and danger networks. The relation network assigns each agent a confidence level reflecting the perceived probability of the agent under consideration being a teammate. The danger network then generates a risk ratio by perceiving the task at hand and analyzing the potential loss if a mistake in judgment is made. The confidence level and risk ratio are then combined to select a corresponding policy in the policy module. Then, the agent acts upon the selected policy.
